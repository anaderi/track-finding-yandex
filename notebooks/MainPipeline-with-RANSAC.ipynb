{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # Building alternative pipeline\n",
    "# \n",
    "# * Prepare Hough transform based only on wire information (= energy, time, radial distance)\n",
    "# * Build predictions based on Hough, local information, and local information of left/right neighbors\n",
    "# \n",
    "\n",
    "# In[1]:\n",
    "\n",
    "get_ipython().magic(u'run visualizations.ipynb')\n",
    "import sys\n",
    "sys.path.insert(0, '../modules')\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "from hits import AllHits, CyDetHits\n",
    "hits = CyDetHits('../data/signal_TDR.root', signal_coding=[0])\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "import pandas\n",
    "from tracking import HoughSpace\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "# ### Collect (Raw) Wire Features \n",
    "\n",
    "# In[21]:\n",
    "\n",
    "right_neighs = numpy.array([hits.cydet.shift_wire(wire, 1) for wire in range(hits.cydet.n_points)])\n",
    "left_neighs = numpy.array([hits.cydet.shift_wire(wire, -1) for wire in range(hits.cydet.n_points)])\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "# Energy deposits\n",
    "deposits = numpy.vstack(hits.get_energy_deposits(i) for i in range(hits.n_events))\n",
    "deposits *= 100 # to avoid small numbers for GBRT\n",
    "# Time after triggering that signal waveforms starts\n",
    "rel_time = numpy.vstack(hits.get_relative_time(i) for i in range(hits.n_events))\n",
    "# Truth Values\n",
    "labels = numpy.vstack(hits.get_hit_types(i) for i in range(hits.n_events))\n",
    "# Layer ID of hit wires\n",
    "layer_id = numpy.vstack(hits.cydet.point_rhos for i in range(hits.n_events))\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "labels.shape, deposits.shape\n",
    "\n",
    "\n",
    "# ## Convenience Functions for Data\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "def flatten_data(data, keys, samples, n_features):\n",
    "    data_flat = data[samples].reshape(-1, n_feats)\n",
    "    return pandas.DataFrame(data=data_flat, columns=keys)\n",
    "\n",
    "def mask(data, pol=None):\n",
    "    if pol==None:\n",
    "        return data[data['labels'] != 0]\n",
    "    if pol==0:\n",
    "        return data[(data['labels'] != 0) & (data['Polarity'] == 0)]\n",
    "    if pol==1:\n",
    "        return data[(data['labels'] != 0) & (data['Polarity'] != 0)]\n",
    "\n",
    "def predict_classifier(classifier, data_samp):\n",
    "    \"\"\"\n",
    "    Return predictions where no hit has zero response by definition.  Return both\n",
    "    flat predictions, and event sorted predicitions\n",
    "    \"\"\"\n",
    "    # Get the predictions\n",
    "    pred_evt = classifier.predict_proba(data_samp)[:,1]\n",
    "\n",
    "    # Check which wires have hits, which ones do not\n",
    "    not_hit = (data_samp['labels'] == 0).values\n",
    "    has_hit = (data_samp['labels'] != 0).values\n",
    "\n",
    "    # Define hit-less wires as definitely not being signal\n",
    "    pred_evt[not_hit] = 0\n",
    "\n",
    "    # Slim down the result to a copy with only hits\n",
    "    pred = pred_evt[has_hit]\n",
    "    # Reshape the result to be the event shape, for the hoguh transform\n",
    "    pred_evt = pred_evt.reshape(-1, hits.cydet.n_points)\n",
    "    \n",
    "    return pred, pred_evt\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "## Look up table to map from events to hits\n",
    "event_to_hit_look = np.arange(hits.n_events*hits.cydet.n_points).reshape(hits.n_events, -1)\n",
    "\n",
    "\n",
    "# ## Train/test splitting \n",
    "\n",
    "# In[27]:\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "rest, sample_3 = train_test_split(range(len(labels)), train_size=0.6, test_size=0.3)\n",
    "sample_1, sample_2 = train_test_split(rest, train_size=0.5, test_size=0.5)\n",
    "\n",
    "\n",
    "# ## Features for Wire GBDT\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "from collections import OrderedDict\n",
    "features = OrderedDict()\n",
    "# Wire features\n",
    "features['deposit'] = deposits * 100\n",
    "features['rel_time'] = rel_time\n",
    "features['layer_id'] = layer_id\n",
    "\n",
    "# LR-Neighbour Features\n",
    "features['r_deposit'] = (deposits * 100)[:, right_neighs]\n",
    "features['r_rel_time'] = rel_time[:, right_neighs]\n",
    "features['l_deposit'] = (deposits * 100)[:, left_neighs]\n",
    "features['l_rel_time'] = rel_time[:, left_neighs]\n",
    "\n",
    "# Truth values\n",
    "features['labels'] = labels\n",
    "features['is_signal'] =  numpy.take([0, 1, 0], labels)\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "# Define Data\n",
    "train_features = features.keys()[:-2]\n",
    "data = numpy.dstack(features.values())\n",
    "n_feats = data.shape[-1]\n",
    "print data.shape\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "data_1, data_2, data_3 = [flatten_data(data, features.keys(), samp, n_feats) \n",
    "                          for samp in [sample_1, sample_2, sample_3]]\n",
    "\n",
    "\n",
    "# ## NeighbourLevel GBDT\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "from rep.metaml.factory import ClassifiersFactory\n",
    "from rep.estimators import SklearnClassifier, TMVAClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from rep.report.metrics import RocAuc\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "factory = ClassifiersFactory()\n",
    "\n",
    "# Define GBDT over neighbour-level features\n",
    "neigh_gbdt = SklearnClassifier(GradientBoostingClassifier(n_estimators=100), \n",
    "                                    features=train_features)\n",
    "# Add the GBDT\n",
    "factory.add_classifier('Local and Neighbour Features', neigh_gbdt)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "# Train the classifier\n",
    "factory.fit(mask(data_1), mask(data_1)['is_signal'])\n",
    "pass\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "print np.unique(labels)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "# Print these predictions\n",
    "pred_2, pred_evt_2 = predict_classifier(neigh_gbdt, data_2)\n",
    "\n",
    "\n",
    "# ## Testing hough  \n",
    "\n",
    "# In[36]:\n",
    "\n",
    "# Define which wires we want to correct as hits which were missclassified \n",
    "problem_weights_2 = (mask(data_2)['labels'] != 0) * abs(mask(data_2)['is_signal'] - pred_2) ** 2\n",
    "\n",
    "\n",
    "# ### Quality of classification, reweighted to highlight mislabelled hits\n",
    "# Second scoring is used later to measure quality of Hough transform\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "print roc_auc_score(mask(data_2)['is_signal'], pred_2)\n",
    "print roc_auc_score(mask(data_2)['is_signal'], pred_2, sample_weight=problem_weights_2)\n",
    "\n",
    "\n",
    "# ### Define correspondence matrix separately for even/odd, use several radii\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "from tracking import HoughSpace\n",
    "\n",
    "default = [[31.5, 34, 34.5, 2]]\n",
    "submatrices = []\n",
    "\n",
    "# Define even and odd layer wires\n",
    "even_wires = hits.cydet.point_pol != 1\n",
    "odd_wires = hits.cydet.point_pol == 1\n",
    "\n",
    "# TODO test with several radii\n",
    "for rmin, rmean, rmax, rsgma in default: #[[30, 33, 35], [26, 29, 32]]:\n",
    "    # Try with default values\n",
    "    hough = HoughSpace(hits, sig_rho_min=rmin, sig_rho=rmean, sig_rho_max=rmax, sig_rho_sgma=rsgma)\n",
    "    corresp = hough.correspondence\n",
    "    submatrices.append(corresp)\n",
    "\n",
    "# Stack all submatricies horizontally\n",
    "new_correspondence = sparse.hstack(submatrices)\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "# Check the shape, and the number of non-zero entries\n",
    "new_correspondence.shape, new_correspondence.nnz\n",
    "\n",
    "\n",
    "# ## Rotation of Even Layers from Hough Output\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "def plot_hough_shift(int_even, int_odd, this_phi, savedir=None):\n",
    "    dphi = (2.*np.pi)/len(int_even)\n",
    "    phi_bins = dphi*np.arange(len(int_even))\n",
    "    plt.bar(phi_bins, int_even, alpha=0.5, width=dphi)\n",
    "    plt.bar(phi_bins, int_odd, color=\"red\",alpha=0.5, width=dphi)\n",
    "    plt.title(r\"Track Center Weights vs. $\\phi$\")\n",
    "    plt.xlabel(r\"$\\phi$\")\n",
    "    plt.ylabel(r\"Track Center Weights (Integrated over $\\rho$)\")\n",
    "    plt.xlim([0,2*np.pi])\n",
    "    if savedir != None:\n",
    "        plt.savefig(savedir+\"hough_by_phi.png\")\n",
    "    show()\n",
    "    plt.bar(phi_bins, int_even, alpha=0.5, width=dphi)\n",
    "    plt.bar(np.roll(phi_bins, this_phi), int_odd, color=\"red\",alpha=0.5, width=dphi)\n",
    "    plt.title(r\"Shifted Track Center Weights vs. $\\phi$\")\n",
    "    plt.xlabel(r\"$\\phi$\")\n",
    "    plt.ylabel(r\"Track Center Weights (Integrated over $\\rho$)\")\n",
    "    plt.xlim([0,2*np.pi])\n",
    "    if savedir != None:\n",
    "        plt.savefig(savedir+\"s_hough_by_phi.png\")\n",
    "    show()\n",
    "\n",
    "\n",
    "# ## Traning second classifier\n",
    "\n",
    "# ### Hough Image Without Shift\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "from tracking import HoughTransformer, HoughShifter\n",
    "# Fit and transform the second data sample\n",
    "hough_transformer = HoughTransformer(new_correspondence, hough.norm_track_neighs, pred_evt_2, alpha_max=2., alpha_rw=2.)\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "# Predict for third sample\n",
    "pred_3, pred_evt_3 = predict_classifier(neigh_gbdt, data_3)\n",
    "\n",
    "# Get the hough results\n",
    "hough_result_2, hough_image_2 = hough_transformer.transform(pred_evt_2)\n",
    "hough_result_3, hough_image_3 = hough_transformer.transform(pred_evt_3)\n",
    "\n",
    "\n",
    "# ### Hough Image With Shift\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "# Do the first transform to get the hough space that needs to be aligned\n",
    "aligner = HoughTransformer(new_correspondence, hough.norm_track_neighs, pred_evt_2, alpha_rw=2., alpha_max=2.)\n",
    "_ , to_align_2 = aligner.transform(pred_evt_2)\n",
    "_ , to_align_3 = aligner.transform(pred_evt_3)\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "# Shift this hough space to get the even and odd layers agreeing\n",
    "hough_shifter_2 = HoughShifter(hough, 10, -10)\n",
    "hough_shifter_3 = HoughShifter(hough, 10, -10)\n",
    "\n",
    "# Get the images\n",
    "hough_image_even_3 = to_align_3[:,:hough.track.n_points]\n",
    "hough_image_odd_3 = to_align_3[:,hough.track.n_points:]\n",
    "# Fit the shifter\n",
    "ideal_rotate_3, integral_even_3, integral_odd_3 =    hough_shifter_3.fit_shift(hough_image_even_3, hough_image_odd_3)\n",
    "# Shift the result\n",
    "shift_pred_evt_3 = hough_shifter_3.shift_result(pred_evt_3)\n",
    "shift_labels_3 = hough_shifter_3.shift_result(features['labels'][sample_3])\n",
    "\n",
    "# Get the images\n",
    "hough_image_even_2 = to_align_2[:,:hough.track.n_points]\n",
    "hough_image_odd_2 = to_align_2[:,hough.track.n_points:]\n",
    "# Fit the shifter\n",
    "ideal_rotate_2, integral_even_2, integral_odd_2 =    hough_shifter_2.fit_shift(hough_image_even_2, hough_image_odd_2)\n",
    "# Shift the result\n",
    "shift_pred_evt_2 = hough_shifter_2.shift_result(pred_evt_2)\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "# Hough Transform on the shifted results\n",
    "shifted_hough_result_3, shifted_hough_image_3 = hough_transformer.transform(shift_pred_evt_3)\n",
    "shifted_hough_result_2, shifted_hough_image_2 = hough_transformer.transform(shift_pred_evt_2)\n",
    "\n",
    "# Unshift the results to add them as a feature\n",
    "unshifted_hough_result_3 = hough_shifter_3.shift_result(shifted_hough_result_3, backward=True)\n",
    "unshifted_hough_result_2 = hough_shifter_2.shift_result(shifted_hough_result_2, backward=True)\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "# Add these as features\n",
    "data_2['Hough'] = hough_result_2.flatten()\n",
    "data_2['Shift_Hough'] = unshifted_hough_result_2.flatten()\n",
    "\n",
    "data_3['Hough'] = hough_result_3.flatten()\n",
    "data_3['Shift_Hough'] = unshifted_hough_result_3.flatten()\n",
    "\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "# Add this to the feature list\n",
    "train_features_full = train_features + ['Hough']\n",
    "train_features_shift = train_features + ['Shift_Hough']\n",
    "\n",
    "# Define the new classifier\n",
    "hough_gbdt = SklearnClassifier(GradientBoostingClassifier(n_estimators=100), \n",
    "                               features=train_features_full) \n",
    "\n",
    "s_hough_gbdt = SklearnClassifier(GradientBoostingClassifier(n_estimators=100), \n",
    "                               features=train_features_shift) \n",
    "\n",
    "# Define GBDT over only energy deposit to compare\n",
    "dep_gbdt = SklearnClassifier(GradientBoostingClassifier(n_estimators=200), \n",
    "                               features=['deposit'])\n",
    "\n",
    "# Ensure neigh-level GBDT has enough trees to compare properly\n",
    "neigh_gbdt.set_params(n_estimators=200)\n",
    "\n",
    "# Add the classifiers\n",
    "factory.add_classifier('Shift Hough, Local and Neighbour Features', s_hough_gbdt)\n",
    "factory.add_classifier('Hough, Local and Neighbour Features', hough_gbdt)\n",
    "factory.add_classifier('Energy Deposition', dep_gbdt)\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "# Train the classifier\n",
    "factory.fit(mask(data_2), mask(data_2)['is_signal'])\n",
    "pass\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "# Test it on the last set of data\n",
    "pred_final_diag_3 = factory.test_on(mask(data_3), mask(data_3)['is_signal'])\n",
    "pred_final_3, pred_final_evt_3 = predict_classifier(hough_gbdt, data_3)\n",
    "pred_final_shift_3, pred_final_shift_evt_3 = predict_classifier(s_hough_gbdt, data_3)\n",
    "pred_3, pred_evt_3 = predict_classifier(neigh_gbdt, data_3)\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "# TODO clean this up\n",
    "figsize(6.4,6.4) \n",
    "feat_label_dict = OrderedDict([\n",
    "            ('l_rel_time' , \"Left Timing\"),  \n",
    "            ('r_rel_time' , \"Right Timing\"),\n",
    "            (\"layer_id\" , \"R Distance\"), \n",
    "            ('r_deposit' , 'Right Energy'), \n",
    "            ('l_deposit' , 'Left Energy'), \n",
    "            ('rel_time' , \"Timing\"),\n",
    "            ('deposit' , 'Energy'), \n",
    "            ('Hough' , r\"Hough, $W_j''$\"),\n",
    "            ('Shift_Hough' , r\"Shift Hough, $W_j'''$\"),\n",
    "        ])\n",
    "\n",
    "def plot_feature_importance(rep_classifier, feat_label_dict):\n",
    "    feat_import = rep_classifier.get_feature_importances()\n",
    "    feat_import = feat_import.sort(\"effect\", ascending=False)\n",
    "    ax = plt.subplot(111)\n",
    "    ax.bar( np.arange(len(feat_import.values)), feat_import.values,zorder=10)\n",
    "    ax.set_xticks(np.arange(len(feat_import.values))+0.5)\n",
    "    ax.minorticks_on()\n",
    "    ax.set_ylabel(\"Normalized Relative Usage\")\n",
    "    ax.set_title(\"Feature Importance\")\n",
    "    ax.autoscale()\n",
    "    ax.grid(b=True, which='major', axis='y' ,color='grey', linestyle='--')\n",
    "    ax.grid(b=True, which='minor', axis='y' , color='grey', linestyle=':')\n",
    "    ordered_labels = OrderedDict((key, feat_label_dict[key]) for key in feat_import.index.values)\n",
    "    ax.set_xticklabels(ordered_labels.values(),  rotation='vertical')\n",
    "    ax.set_yticklabels([\"{:.0f}%\".format(tick*100) for tick in ax.get_yticks()])\n",
    "    return ax\n",
    "\n",
    "def plot_feature_correlations(rep_factory, feat_label_dict):\n",
    "    corr = pred_final_diag_3.features_correlation_matrix(features=train_features+[\"Hough\"],\n",
    "                                tick_labels=[feat_label_dict[key] for key in train_features_full])\n",
    "    corr.fontsize = 15\n",
    "    corr.cmap = \"RdBu\"\n",
    "    return corr.plot()\n",
    "\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "hough_level = factory[\"Hough, Local and Neighbour Features\"]\n",
    "plot_feature_importance(hough_level, feat_label_dict)\n",
    "show()\n",
    "plot_feature_correlations(factory, feat_label_dict)\n",
    "show()\n",
    "\n",
    "feat_label_dict['Hough'] = r\"Shifted Hough, $W_j''$\"\n",
    "s_hough_level = factory[\"Shift Hough, Local and Neighbour Features\"]\n",
    "plot_feature_importance(s_hough_level, feat_label_dict)\n",
    "show()\n",
    "plot_feature_correlations(factory, feat_label_dict)\n",
    "show()\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "plot_feature( (data_3['Hough'].values+0.1), data_3['labels'].values, \n",
    "             xlabel=\"Hough Output\", ylabel=\"Normalised Hit Count\", xlog=True,\n",
    "            title=\"Reweighted Inverse Hough Output Distribution\", nbins=20)\n",
    "\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "plot_feature( (data_3['Shift_Hough'].values+0.1), data_3['labels'].values, \n",
    "             xlabel=\"Shifted Hough Output\", ylabel=\"Normalised Hit Count\", xlog=True,\n",
    "            title=\"Reweighted Inverse Hough Output Distribution\", nbins=20)\n",
    "\n",
    "\n",
    "# \n",
    "# ## Final quality of signal vs bck wires\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "print roc_auc_score(mask(data_3)['is_signal'], pred_final_3)\n",
    "print roc_auc_score(mask(data_3)['is_signal'], pred_final_shift_3)\n",
    "\n",
    "figsize(11,6) \n",
    "plot_rocs(mask(data_3)[\"is_signal\"], pred_final_diag_3.prediction, zoom=False)\n",
    "plt.savefig(\"/home/elg112/COMET/Presentations_Papers/group_meetings/images/tmva_roc.png\", bbox_inches=\"tight\")\n",
    "show()\n",
    "plot_rocs(mask(data_3)[\"is_signal\"], pred_final_diag_3.prediction, zoom=True)\n",
    "plt.savefig(\"/home/elg112/COMET/Presentations_Papers/group_meetings/images/tmva_roc_zoom.png\", bbox_inches=\"tight\")\n",
    "show()\n",
    "\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "plot_feature( pred_3, mask(data_3)['labels'].values, \n",
    "             xlabel=\"Track Level GBDT Output\", ylabel=\"Normalised Hit Count\", \n",
    "            title=\"Track Level GBDT Output Distribution\", nbins=20)\n",
    "show()\n",
    "plot_feature( pred_final_3, mask(data_3)['labels'].values, \n",
    "             xlabel=\"Track Level GBDT Output\", ylabel=\"Normalised Hit Count\",\n",
    "            title=\"Track Level GBDT Output Distribution\", nbins=20)\n",
    "show()\n",
    "plot_feature( pred_final_shift_3, mask(data_3)['labels'].values, \n",
    "             xlabel=\"Track Level GBDT Output\", ylabel=\"Normalised Hit Count\",\n",
    "            title=\"Track Level GBDT Output Distribution\", nbins=20)\n",
    "show()\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "problem_weights_3 = (mask(data_3)['labels'] != 0) * abs(mask(data_3)['is_signal'] - pred_3) ** 2\n",
    "print roc_auc_score(mask(data_3)['is_signal'], pred_3)\n",
    "print roc_auc_score(mask(data_3)['is_signal'], pred_3, sample_weight=problem_weights_3)\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "problem_weights_3 = (mask(data_3)['labels'] != 0) * abs(mask(data_3)['is_signal'] - pred_final_shift_3) ** 2\n",
    "print roc_auc_score(mask(data_3)['is_signal'], pred_final_shift_3)\n",
    "print roc_auc_score(mask(data_3)['is_signal'], pred_final_shift_3, sample_weight=problem_weights_3)\n",
    "\n",
    "\n",
    "# ##RANSAC Implimentation\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "from sklearn import linear_model\n",
    "#print linear_model.LinearRegression__doc__\n",
    "#print linear_model.RANSACRegressor.__doc__\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "# Get the actual circle parameters for the fit from the linearized parameters\n",
    "def get_circle(x_coeff, y_coeff, intercept):\n",
    "    return x_coeff/2, y_coeff/2, np.sqrt(4*intercept + x_coeff**2 + y_coeff**2)/2\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "# Check that the fit returns a circle that passes through the production target\n",
    "def inside_target(model, X, y):\n",
    "    a, b, r = get_circle(model.coef_[0][0], model.coef_[0][1], model.intercept_)\n",
    "    return abs(np.sqrt(a**2 + b**2) - r) < 10\n",
    "\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "# Geometric considerations for the fit\n",
    "wire_x, wire_y = hits.cydet.get_points_xs_and_ys()\n",
    "# Linearize the input problem\n",
    "wire_xy = np.vstack([wire_x, wire_y]).T\n",
    "wire_z  = np.square(wire_x) + np.square(wire_y)\n",
    "        \n",
    "def ransac_fit(labels, preds, min_hits=13, plot=False):\n",
    "    # Initialze parameters\n",
    "    x1, y1, r1 = -1.*np.zeros(2), -1.*np.zeros(2), -1.*np.zeros(2)\n",
    "    x2, y2, r2 = -1.*np.zeros(2), -1.*np.zeros(2), -1.*np.zeros(2)\n",
    "    this_score = -1.*np.ones(wire_z.shape[0])\n",
    "    \n",
    "    # Get wires to fit\n",
    "    even_sig = even_wires & preds\n",
    "    odd_sig = odd_wires & preds\n",
    "    \n",
    "    # Plot the input to the fit\n",
    "    if plot:\n",
    "        plot_output(to_plot, hits.cydet, size=40*preds)\n",
    "        plot_add_outlines(to_plot, hits.cydet)\n",
    "\n",
    "    # Skip if either layer does not have enough hit points\n",
    "    # if (sum(even_sig) < min_hits) or (sum(odd_sig) < min_hits):\n",
    "    #     print \"Skipped\"\n",
    "    #    if plot:\n",
    "    #        show()\n",
    "    #    return\n",
    "\n",
    "    for pol, signal in enumerate([even_sig, odd_sig]):\n",
    "\n",
    "        # Get the points to fit\n",
    "        fit_x, fit_y = wire_x[signal], wire_y[signal]\n",
    "        fit_xy = np.vstack([fit_x,fit_y]).T\n",
    "        # Linearize the equation\n",
    "        fit_z = np.square(fit_x) + np.square(fit_y)\n",
    "\n",
    "        # Fit line using all data\n",
    "        model = linear_model.LinearRegression()\n",
    "        try:\n",
    "            model.fit(fit_xy, fit_z)\n",
    "        except ValueError:\n",
    "            if plot:\n",
    "                print \"Skipped Normal\"\n",
    "                show()\n",
    "            return x1, y1, r1, x2, y2, r2, this_score\n",
    "        \n",
    "        # Robustly fit linear model with RANSAC algorithm\n",
    "        model_ransac = linear_model.RANSACRegressor(linear_model.LinearRegression(),\n",
    "                                                   is_model_valid=inside_target,\n",
    "                                                   max_trials=1000)\n",
    "        try:\n",
    "            model_ransac.fit(fit_xy, fit_z)\n",
    "        except ValueError:\n",
    "            if plot:\n",
    "                print \"Skipped RANSAC\"\n",
    "                show()\n",
    "            return x1, y1, r1, x2, y2, r2, this_score\n",
    "        \n",
    "        inlier_mask = signal[model_ransac.inlier_mask_]\n",
    "        outlier_mask = signal[np.logical_not(model_ransac.inlier_mask_)]\n",
    "\n",
    "        # Plot the output\n",
    "        labels = np.zeros(hits.cydet.n_points)\n",
    "        labels[inlier_mask] = 1\n",
    "        labels[outlier_mask] = 2\n",
    "\n",
    "        # Get the regular fit\n",
    "        x1[pol], y1[pol], r1[pol] = get_circle(model.coef_[0], model.coef_[1] , model.intercept_)\n",
    "\n",
    "        # Get the RANSAC fit\n",
    "        x2[pol], y2[pol], r2[pol] = get_circle(model_ransac.estimator_.coef_[0][0], \n",
    "                         model_ransac.estimator_.coef_[0][1] , model_ransac.estimator_.intercept_)\n",
    "\n",
    "        # Make sure we're plotting all points\n",
    "        assert len(inlier_mask) + len(outlier_mask) == sum(signal),            \"{} {}\".format(len(inlier_mask) + len(outlier_mask), len(signal))    \n",
    "        if plot:\n",
    "            plot_add_circle(x1[pol], y1[pol], r1[pol])\n",
    "            print \"Fit:\" + str(r1[pol])\n",
    "            plot_add_circle(x2[pol], y2[pol], r2[pol], color=\"red\")\n",
    "            print \"RANSAC Fit:\" + str(r2[pol]) + \"\\n\"\n",
    "\n",
    "        # Score the wires by distance from RANSAC\n",
    "        this_score = model_ransac.estimator_.predict(wire_xy)[:,0]\n",
    "        this_score -= wire_z\n",
    "        this_score = np.absolute(this_score)\n",
    "    if plot:\n",
    "        show()\n",
    "    return x1, y1, r1, x2, y2, r2, this_score\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "# Define threshold GBDT output to fit to\n",
    "fpr, tpr, values =  roc_curve(mask(data_3)['is_signal'], pred_final_3)\n",
    "threshold = np.where(tpr > 0.99)[0][0]\n",
    "print \"TPR: {}\".format(tpr[threshold]),      \"FPR: {}\".format(fpr[threshold]),      \"VALUE: {}\".format(values[threshold])\n",
    "\n",
    "# Define the wires to be fit and their locations\n",
    "cut_pred_final_3 = pred_final_evt_3 > values[threshold]\n",
    "fit_evts = cut_pred_final_3.shape[0]\n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "# Score the wires by distance from RANSAC\n",
    "score = np.zeros(data_3['labels'].shape[0]) \n",
    "for evt in range(len(sample_3)):\n",
    "    if evt%100 == 0:\n",
    "        print evt\n",
    "    evt_hits = event_to_hit_look[evt]\n",
    "    to_fit = data_3[\"labels\"].values[evt_hits]\n",
    "    output = ransac_fit(to_fit, cut_pred_final_3[evt,:])\n",
    "    if output != None:\n",
    "        score[evt_hits] =  output[-1]\n",
    "data_3['score'] = score\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "good_events = data_3[data_3['score'] != -1].shape[0]/4482\n",
    "total_events = data_3.shape[0]/4482\n",
    "print good_events/float(total_events)\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "plot_feature((mask(data_3)[data_3['score'] != -1]['score'].values +0.001), \n",
    "             mask(data_3)[data_3['score'] != -1]['labels'].values, xlog=True,\n",
    "             xlabel=\"Track Level GBDT Output\", ylabel=\"Normalised Hit Count\",\n",
    "            title=\"Track Level GBDT Output Distribution\", nbins=20)\n",
    "show()\n",
    "\n",
    "\n",
    "# ## Visualization of Progress of Algorithm\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "# Event information\\\n",
    "event = 7\n",
    "add_trans = True\n",
    "save = False\n",
    "savedir = \"/home/elg112/COMET/Presentations_Papers/HEP_Summer_School/images/algorithm_0/\"\n",
    "\n",
    "evt_hits = event_to_hit_look[event]\n",
    "to_plot = data_3[\"labels\"].values[evt_hits]\n",
    "hough_output = data_3[\"Hough\"].values[evt_hits]\n",
    "plot_hough_image_3 = hough_image_3[event,:hough.track.n_points] + hough_image_3[event,hough.track.n_points:]\n",
    "\n",
    "# Shifted plot information\n",
    "shift_plot = shift_labels_3[event]\n",
    "shift_hough_output = shifted_hough_result_3[event,:]\n",
    "shift_hough_image = shifted_hough_image_3[event,:hough.track.n_points] +                    shifted_hough_image_3[event,hough.track.n_points:]\n",
    "\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "# Basic output\n",
    "plot_output(to_plot, hits.cydet)\n",
    "show()\n",
    "\n",
    "# First GBDT output\n",
    "plot_output(to_plot, hits.cydet, size=plot_norm_size(pred_evt_3[event,:]))\n",
    "plot_add_outlines(to_plot, hits.cydet)\n",
    "if save:\n",
    "    plt.savefig(savedir+\"plot_neigh_level.png\", bbox_inches='tight')\n",
    "show()\n",
    "\n",
    "# Hough output\n",
    "plot_output(to_plot, hits.cydet, size=plot_norm_size(pred_evt_3[event,:]), add_transform=add_trans)\n",
    "plot_add_tracks(hits.cydet, hough, size=plot_norm_size(plot_hough_image_3,40))\n",
    "if save:\n",
    "    plt.savefig(savedir+\"plot_hough.png\", bbox_inches='tight')\n",
    "show()\n",
    "\n",
    "# Inverse Hough output\n",
    "plot_output(to_plot, hits.cydet, size=plot_norm_size(hough_output))\n",
    "plot_add_tracks(hits.cydet, hough, size=plot_norm_size(plot_hough_image_3,40), add_transform=add_trans,\n",
    "                tolerance=0.00)\n",
    "if save:\n",
    "    plt.savefig(savedir+\"plot_inv_hough.png\", bbox_inches='tight')\n",
    "show()    \n",
    "\n",
    "# Shift in Hough Space\n",
    "# TODO magic number here\n",
    "plot_hough_shift(integral_even_3[event,:], integral_odd_3[event,:], \n",
    "                 hough_shifter_3.rotate_index[event]+hough_shifter_3.lower_lim, \n",
    "                 savedir=savedir)\n",
    "show()\n",
    "\n",
    "# Hough output\n",
    "plot_output(shift_plot, hits.cydet, size=plot_norm_size(shift_pred_evt_3[event,:]), add_transform=add_trans)\n",
    "plot_add_tracks(hits.cydet, hough, size=plot_norm_size(shift_hough_image,40))\n",
    "if save:\n",
    "    plt.savefig(savedir+\"plot_shft_hough.png\",  bbox_inches='tight')\n",
    "show()\n",
    "\n",
    "# Inverse Hough output\n",
    "plot_output(shift_plot, hits.cydet, size=plot_norm_size(shift_hough_output))\n",
    "plot_add_tracks(hits.cydet, hough, size=plot_norm_size(shift_hough_image,40), add_transform=add_trans,\n",
    "                tolerance=0.00)\n",
    "if save:\n",
    "    plt.savefig(savedir+\"plot_shft_inv_hough.png\")\n",
    "show()\n",
    "\n",
    "# Final\n",
    "plot_output(to_plot, hits.cydet, size=plot_norm_size(pred_final_evt_3[event,:]))\n",
    "if save:\n",
    "    plt.savefig(savedir+\"plot_shft_inv_hough.png\")\n",
    "show()\n",
    "\n",
    "# RANSAC \n",
    "print ransac_fit(to_plot, cut_pred_final_3[event,:], plot=True)\n",
    "\n",
    "\n",
    "# In[72]:\n",
    "\n",
    "# Belle-II literature\n",
    "# multiple radii\n",
    "# optimize hough to improve track purity, use RANSAC to shed background islands\n",
    "# \n",
    "\n",
    "#TODO Offline Analysis\n",
    "# WEDS clean up RANSAC implimentation\n",
    "# WEDS use shifted hough in RANSAC implimentation\n",
    "# THURS penalize on no hits for RANSAC\n",
    "# THURS change sampling probability via GBDT score\n",
    "# THURS change scoring weight by GBDT score\n",
    "# FRI check results for mulitple radii, no optimization\n",
    "# FRI check results for varying hit efficiencies, no optimization\n",
    "\n",
    "\n",
    "# In[73]:\n",
    "\n",
    "#TODO Online\n",
    "# TUES Rebuild notebook for new sample\n",
    "# TUES Integrate trigger signal in\n",
    "# TUES Reevaluate the flow of the algorithm\n",
    "\n",
    "\n",
    "# In[74]:\n",
    "\n",
    "# MC PRODUCTION\n",
    "# Timing in Prod. Sec.\n",
    "#  Determine IO and CPU time for current jobs\n",
    "#  Determine best cuts to make (most obvious ones anyway)\n",
    "# ECAL hits\n",
    "#  After CM18\n",
    "# Cross-Check occupancy\n",
    "#  Generate large enough CyDet sample and check occupancy\n",
    "#  Perhaps do this locally, or atleast the merging part\n",
    "\n",
    "\n",
    "# In[75]:\n",
    "\n",
    "# NOTES\n",
    "## Shifting to align image in hough space must \n",
    "#  play well with the placticity already \n",
    "#  implimented in the algorithm.  Adjust reweighting\n",
    "## Try reweighting background hits close to signal hits\n",
    "#  as worse when we do the track level GBDT algo.  Rid\n",
    "#  background islands at RANSAC level.\n",
    "\n",
    "# Reject Non-event\n",
    "# Ideal case finding\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
